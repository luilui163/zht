Introduction 1
1 Stochastic simulation 9
1.1 Introduction 9
1.2 Generation of discrete random quantities 10
1.2.1 Bernoulli distribution 11
1.2.2 Binomial distribution 11
1.2.3 Geometric and negative binomial distribution 12
1.2.4 Poisson distribution 12
1.3 Generation of continuous random quantities 13
1.3.1 Probability integral transform 13
1.3.2 Bivariate techniques 14
1.3.3 Methods based on mixtures 17
1.4 Generation of random vectors and matrices 20
1.4.1 Multivariate normal distribution 21
1.4.2 Wishart distribution 23
1.4.3 Multivariate Student¡¯s t distribution 24
1.5 Resampling methods 25
1.5.1 Rejection method 25
1.5.2 Weighted resampling method 30
1.5.3 Adaptive rejection method 32
1.6 Exercises 34
2 Bayesian inference 41
2.1 Introduction 41
2.2 Bayes¡¯ theorem 41
2.2.1 Prior, posterior and predictive distributions 42
2.2.2 Summarizing the information 47
2.3 Conjugate distributions 49
2.3.1 Conjugate distributions for the exponential family 51X Contents
2.3.2 Conjugacy and regression models 55
2.3.3 Conditional conjugacy 58
2.4 Hierarchical models 60
2.5 Dynamic models 63
2.5.1 Sequential inference 64
2.5.2 Smoothing 65
2.5.3 Extensions 67
2.6 Spatial models 68
2.7 Model comparison 72
2.8 Exercises 74
3 Approximate methods of inference 81
3.1 Introduction 81
3.2 Asymptotic approximations 82
3.2.1 Normal approximations 83
3.2.2 Mode calculation 86
3.2.3 Standard Laplace approximation 88
3.2.4 Exponential form Laplace approximations 90
3.3 Approximations by Gaussian quadrature 93
3.4 Monte Carlo integration 95
3.5 Methods based on stochastic simulation 98
3.5.1 Bayes¡¯ theorem via the rejection method 100
3.5.2 Bayes¡¯ theorem via weighted resampling 101
3.5.3 Application to dynamic models 104
3.6 Exercises 106
4 Markov chains 113
4.1 Introduction 113
4.2 Definition and transition probabilities 114
4.3 Decomposition of the state space 118
4.4 Stationary distributions 121
4.5 Limiting theorems 124
4.6 Reversible chains 127
4.7 Continuous state spaces 129
4.7.1 Transition kernels 129
4.7.2 Stationarity and limiting results 131
4.8 Simulation of a Markov chain 132
4.9 Data augmentation or substitution sampling 135
4.10 Exercises 136
5 Gibbs sampling 141
5.1 Introduction 141
5.2 Definition and properties 142
5.3 Implementation and optimization 1485.3.1 Forming the sample 148
5.3.2 Scanning strategies 150
5.3.3 Using the sample 151
5.3.4 Reparametrization 152
5.3.5 Blocking 155
5.3.6 Sampling from the full conditional distributions 156
5.4 Convergence diagnostics 157
5.4.1 Rate of convergence 158
5.4.2 Informal convergence monitors 159
5.4.3 Convergence prescription 161
5.4.4 Formal convergence methods 164
5.5 Applications 169
5.5.1 Hierarchical models 169
5.5.2 Dynamic models 172
5.5.3 Spatial models 176
5.6 MCMC-based software for Bayesian modeling 178
Appendix 5.A: BUGS code for Example 5.7 182
Appendix 5.B: BUGS code for Example 5.8 184
5.7 Exercises 184
6 Metropolis-Hastings algorithms 191
6.1 Introduction 191
6.2 Definition and properties 193
6.3 Special cases 198
6.3.1 Symmetric chains 198
6.3.2 Random walk chains 198
6.3.3 Independence chains 199
6.3.4 Other forms 204
6.4 Hybrid algorithms 205
6.4.1 Componentwise transition 206
6.4.2 Metropolis within Gibbs 211
6.4.3 Blocking 214
6.4.4 Reparametrization 216
6.5 Applications 217
6.5.1 Generalized linear mixed models 217
6.5.2 Dynamic linear models 223
6.5.3 Dynamic generalized linear models 226
6.5.4 Spatial models 231
6.6 Exercises 234
7 Further topics in M C M C 237
7.1 Introduction 237
7.2 Model adequacy 237
7.2.1 Estimates of the predictive likelihood 238
Contents xixii Contents
7.2.2 Uses of the predictive likelihood 248
7.2.3 Deviance information criterion 253
7.3 Model choice: MCMC over model and parameter spaces 257
7.3.1 Markov chain for supermodels 258
7.3.2 Markov chain with jumps 261
7.3.3 Further issues related to RJMCMC algorithms 270
7.4 Convergence acceleration 271
7.4.1 Alterations to the chain 271
7.4.2 Alterations to the equilibrium distribution 278
7.4.3 Auxiliary variables 282
7.5 Exercises 284